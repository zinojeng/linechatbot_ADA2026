#!/usr/bin/env python3
"""
ä¸Šå‚³ documents è³‡æ–™å¤¾ä¸­çš„ .md æª”æ¡ˆåˆ° Gemini File Search Store
ä½œç‚º chatbot çš„çŸ¥è­˜åº« (RAG - Retrieval-Augmented Generation)
"""
import os
import sys
import asyncio
from pathlib import Path
from google import genai
from google.genai import types

# è¨­å®š
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
DOCUMENTS_DIR = Path("documents")
KNOWLEDGE_BASE_STORE_NAME = "chatbot_knowledge_base"  # çŸ¥è­˜åº«åç¨±

# é©—è­‰ API Key
if not GOOGLE_API_KEY:
    print("éŒ¯èª¤ï¼šè«‹è¨­å®š GOOGLE_API_KEY ç’°å¢ƒè®Šæ•¸")
    print("åŸ·è¡Œæ–¹å¼ï¼šexport GOOGLE_API_KEY='your_api_key_here'")
    sys.exit(1)

# åˆå§‹åŒ– GenAI client
client = genai.Client(api_key=GOOGLE_API_KEY)
print(f"âœ… GenAI client åˆå§‹åŒ–æˆåŠŸ")


def get_or_create_knowledge_base_store(store_display_name: str) -> str:
    """
    å–å¾—æˆ–å»ºç«‹çŸ¥è­˜åº« File Search Store
    Returns: actual_store_name (API è‡ªå‹•ç”¢ç”Ÿçš„åç¨±)
    """
    try:
        # åˆ—å‡ºæ‰€æœ‰ storesï¼Œæª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
        stores = client.file_search_stores.list()
        for store in stores:
            if hasattr(store, 'display_name') and store.display_name == store_display_name:
                print(f"ğŸ“ æ‰¾åˆ°ç¾æœ‰çŸ¥è­˜åº«ï¼š{store.name}")
                return store.name

        # ä¸å­˜åœ¨å‰‡å»ºç«‹æ–°çš„
        print(f"ğŸ“ å»ºç«‹æ–°çŸ¥è­˜åº«ï¼š{store_display_name}")
        store = client.file_search_stores.create(
            config={'display_name': store_display_name}
        )
        print(f"âœ… çŸ¥è­˜åº«å»ºç«‹æˆåŠŸï¼š{store.name}")
        return store.name

    except Exception as e:
        print(f"âŒ å»ºç«‹çŸ¥è­˜åº«æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        sys.exit(1)


async def upload_file_to_store(file_path: Path, store_name: str, display_name: str) -> bool:
    """
    ä¸Šå‚³å–®ä¸€æª”æ¡ˆåˆ° File Search Store
    """
    try:
        print(f"  â¬†ï¸  ä¸Šå‚³ä¸­ï¼š{display_name}")

        # è¨­å®š MIME typeï¼ˆ.md æª”æ¡ˆä½¿ç”¨ text/plainï¼‰
        config_dict = {
            'display_name': display_name,
            'mime_type': 'text/plain'  # Markdown æª”æ¡ˆä½¿ç”¨ text/plain
        }

        operation = client.file_search_stores.upload_to_file_search_store(
            file_search_store_name=store_name,
            file=str(file_path),
            config=config_dict
        )

        # ç­‰å¾…ä¸Šå‚³å®Œæˆ
        max_wait = 60  # ç§’
        elapsed = 0
        while not operation.done and elapsed < max_wait:
            await asyncio.sleep(2)
            operation = client.operations.get(operation)
            elapsed += 2

        if operation.done:
            print(f"  âœ… ä¸Šå‚³æˆåŠŸï¼š{display_name}")
            return True
        else:
            print(f"  â±ï¸  ä¸Šå‚³è¶…æ™‚ï¼š{display_name}")
            return False

    except Exception as e:
        print(f"  âŒ ä¸Šå‚³å¤±æ•—ï¼š{display_name} - {e}")
        return False


def filter_markdown_files(directory: Path) -> list[Path]:
    """
    éæ¿¾å‡º .md æª”æ¡ˆï¼Œæ’é™¤ macOS ç³»çµ±æª”æ¡ˆ
    """
    md_files = []

    if not directory.exists():
        print(f"âŒ è³‡æ–™å¤¾ä¸å­˜åœ¨ï¼š{directory}")
        return md_files

    for file_path in directory.iterdir():
        # åªè™•ç† .md æª”æ¡ˆ
        if not file_path.is_file() or file_path.suffix.lower() != '.md':
            continue

        # æ’é™¤ macOS ç³»çµ±æª”æ¡ˆ
        if file_path.name.startswith('.') or file_path.name.startswith('._'):
            print(f"â­ï¸  è·³éç³»çµ±æª”æ¡ˆï¼š{file_path.name}")
            continue

        md_files.append(file_path)

    return sorted(md_files)


async def upload_knowledge_base():
    """
    ä¸»è¦ä¸Šå‚³æµç¨‹
    """
    print("=" * 60)
    print("ğŸ“š é–‹å§‹ä¸Šå‚³çŸ¥è­˜åº«æª”æ¡ˆåˆ° Gemini File Search")
    print("=" * 60)

    # 1. å–å¾—æˆ–å»ºç«‹çŸ¥è­˜åº« store
    store_name = get_or_create_knowledge_base_store(KNOWLEDGE_BASE_STORE_NAME)

    # 2. æƒæ documents è³‡æ–™å¤¾
    print(f"\nğŸ“‚ æƒæè³‡æ–™å¤¾ï¼š{DOCUMENTS_DIR}")
    md_files = filter_markdown_files(DOCUMENTS_DIR)

    if not md_files:
        print("âš ï¸  æ‰¾ä¸åˆ°ä»»ä½• .md æª”æ¡ˆ")
        return

    print(f"ğŸ“„ æ‰¾åˆ° {len(md_files)} å€‹ .md æª”æ¡ˆ")

    # 3. ä¸Šå‚³æ‰€æœ‰æª”æ¡ˆ
    print(f"\nâ¬†ï¸  é–‹å§‹ä¸Šå‚³æª”æ¡ˆ...")
    success_count = 0
    fail_count = 0

    for file_path in md_files:
        display_name = file_path.name
        success = await upload_file_to_store(file_path, store_name, display_name)

        if success:
            success_count += 1
        else:
            fail_count += 1

    # 4. é¡¯ç¤ºçµæœ
    print("\n" + "=" * 60)
    print("ğŸ“Š ä¸Šå‚³çµæœçµ±è¨ˆ")
    print("=" * 60)
    print(f"âœ… æˆåŠŸï¼š{success_count} å€‹æª”æ¡ˆ")
    print(f"âŒ å¤±æ•—ï¼š{fail_count} å€‹æª”æ¡ˆ")
    print(f"ğŸ“ çŸ¥è­˜åº«åç¨±ï¼š{KNOWLEDGE_BASE_STORE_NAME}")
    print(f"ğŸ”‘ Store IDï¼š{store_name}")
    print("\nğŸ’¡ æç¤ºï¼šç¾åœ¨æ‚¨å¯ä»¥åœ¨ LINE Bot ä¸­ä½¿ç”¨é€™äº›æ–‡ä»¶ä½œç‚ºçŸ¥è­˜åº«ï¼")
    print("   åªéœ€åœ¨ç¨‹å¼ç¢¼ä¸­æŸ¥è©¢é€™å€‹ storeï¼ŒGemini å°±èƒ½å¾é€™äº›æ–‡ä»¶ä¸­æ‰¾ç­”æ¡ˆã€‚")
    print("=" * 60)


if __name__ == "__main__":
    # åŸ·è¡Œä¸Šå‚³
    asyncio.run(upload_knowledge_base())
